{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Final IBM Capstone Project"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Introduction \nWelcome to the final IBM Capstone Project. \nNow that you have been equipped with the skills and the tools to use location data to explore a geographical location, over the course of two weeks, you will have the opportunity to be as creative as you want and come up with an idea to leverage the Foursquare location data to explore or compare neighborhoods or cities of your choice or to come up with a problem that you can use the Foursquare location data to solve. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## A. Introduction \n#### Discuss the business problem and who would be interested in this project\n\n### Opening a Chinese Restaurant in Toronto, Canada \nThe provincial capital of Ontario. With a recorded population of 2,731,571 in 2016, it is the most populous city in Canada and the fourth most populous city in North America. Toronto is an international centre of business, finance, arts, and culture, and is recognized as one of the most multicultural and cosmopolitan cities in the world.\n\nWe will analyze the neighborhoods in Toronto to identify the most profitable area based on population density and ethnicity diversity. Toronto is a great place to start the restaurant, but we just need to make sure whether it is a profitable idea or not."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Target Audience\n- Business personal who are looking to open a restaraunt in Toronto\n- Investors looking for a potentially successful restauraunt\n- Freelancers looking to start a franchise \n- Data Scientists who wish to analyze Toronto's neighborhoods \n- New visitors to Toronto who love to eat out often "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## B. Data\n#### Describe the data that will be used to solve the problem and the source of the data."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### B.1 Data Sources\n\na. Toronto's Neighborhood information such as \n- Postal Codes\n- Boroughs\n- Neighborhood Names \nSource: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\n\nb. Toronto's Neighborhood Geographical Information\n- Latitude \n- Longitude\nSource: https://cocl.us/Geospatial_data\n\nc. Population Distribution by Ethnic Diversity \n- Ethnic Origin \nSource: https://en.m.wikipedia.org/wiki/Demographics_of_Toronto#Ethnic_diversity)\n\nd. Toronto's Venues Locations, Names, Categories, Location (in Latitude and Longitude) \nvia Foursquare's explore API \nSource: https://developer.foursquare.com\n\n#### Explanation: \nBy combining all of these data sources, we can create a data summary that will allow target audiences to make the best educated decision for their restaurant "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\na) I\u2019m using \u201cList of Postal code of Canada: M\u201d (https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M) wiki page to get all the information about the neighborhoods present in Toronto. This page has the postal code, borough & the name of all the neighborhoods present in Toronto.\n\nb) Then I\u2019m using \u201chttps://cocl.us/Geospatial_data\u201d csv file to get all the geographical coordinates of the neighborhoods.\n\nc) To get information about the distribution of population by their ethnicity I\u2019m using \u201cDemographics of Toronto\u201d (https://en.m.wikipedia.org/wiki/Demographics_of_Toronto#Ethnic_diversity) wiki page. Using this page I\u2019m going to identify the neighborhoods which are densely populated with Indians as it might be helpful in identifying the suitable neighborhood to open a new Indian restaurant.\n\nd) To get location and other information about various venues in Toronto I\u2019m using Foursquare\u2019s explore API. Using the Foursquare\u2019s explore API (which gives venues recommendations), I\u2019m fetching details about the venues up present in Toronto and collected their names, categories and locations (latitude and longitude). From Foursquare API (https://developer.foursquare.com/docs), I retrieved the following for each venue:\n\nName: The name of the venue.\nCategory: The category type as defined by the API.\nLatitude: The latitude value of the venue.\nLongitude: The longitude value of the venue."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n2.2 Data Cleaning"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\na) Scraping Toronto Neighborhoods Table from Wikipedia"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n!conda install -c conda-forge wikipedia --yes \n\nimport pandas as pd\nimport numpy as np\nimport wikipedia as wp"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "html = wp.page(\"List of postal codes of Canada: M\").html().encode(\"UTF-8\")\ndf = pd.read_html(html, header = 0)[0]\ndf.head()"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'df' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-1-8aeeba79e3d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#DATA CLEANING!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Only process the cells that have an assigned borough. Ignore cells with a borough that is Not assigned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBorough\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Not assigned'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Postcode'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Postalcode'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
                    ]
                }
            ],
            "source": "#DATA CLEANING!!!\n\n#Only process the cells that have an assigned borough. Ignore cells with a borough that is Not assigned.\ndf = df[df.Borough != 'Not assigned']\ndf = df.rename(columns={'Postcode': 'Postal Code'})\n\n#If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough. \n#So for the 9th cell in the table on the Wikipedia page, the value of the Borough and the Neighborhood columns will be Queen's Park.\nfor index, row in df.iterrows():\n    if row['Neighbourhood'] == 'Not assigned':\n        row['Neighbourhood'] = row['Borough']\n\n\ndf = df.groupby(['Borough', 'Postalcode'])['Neighbourhood'].apply(list).apply(lambda x:', '.join(x)).to_frame().reset_index()\n\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\nb) Adding geographical coordinates to the neighborhoods\nNext important step is adding the geographical coordinates to these neighborhoods. To do so I'm extracting the data present in the Geospatial Data csv file and I'm combining it with the existing neighborhood dataframe by merging them both based on the postal code."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Reading the latitude & longitude data from CSV file\n\nimport io\nimport requests\n\nurl = \"https://cocl.us/Geospatial_data\"\nlat_long = requests.get(url).text\nlat_long_df=pd.read_csv(io.StringIO(lat_long))\nlat_long_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# After that I'm merging both the dataframe into one by matching on the postal code.\ntoronto_DF = pd.merge(df,lat_long_df, on='Postalcode')\ntoronto_DF = toronto_DF.rename(columns={'Neighbourhood':'Neighborhood'})\ntoronto_DF.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\nc) Scrap the distribution of population from Wikipedia"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Another factor that can help us in deciding which neighborhood would be best option to open a restaurant is, the distribution of population based on the ethnic diversity for each neighborhood. As this helps us in identifying the neighborhoods which are densely populated with Indian crowd since that neighborhood would be an ideal place to open an Indian restaurant.\n\nScraped the following Wikipedia page, \u201cDemographics of Toronto\u201d in order to obtain the data about the Toronto & the Neighborhoods in it. Compared to all the neighborhoods in Toronto below given neighborhoods only had considerable amount of Indian crowd. We are examing those neighborhood's population to identify the densely populated neighborhoods with Indian population."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#overall population distribution \nhtml = wp.page(\"Demographics of Toronto\").html().encode(\"UTF-8\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#TORONTO & EAST YORK population distribution by ethnicity \nTEY_population_df = pd.read_html(html, header = 0)[13]\nTEY_population_df = TEY_population_df.rename(columns={'%':'Ethnic Origin 1 in %', \n                                                      '%.1':'Ethnic Origin 2 in %',\n                                                     '%.2':'Ethnic Origin 3 in %',\n                                                     '%.3':'Ethnic Origin 4 in %',\n                                                     '%.4':'Ethnic Origin 5 in %',\n                                                     '%.5':'Ethnic Origin 6 in %',\n                                                     '%.6':'Ethnic Origin 7 in %',\n                                                     '%.7':'Ethnic Origin 8 in %',\n                                                     '%.8':'Ethnic Origin 9 in %'})\nTEY_population_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#NORTH YORK population distribution by ethnicity \nNorth_population_df = pd.read_html(html, header = 0)[14]\nNorth_population_df = North_population_df.rename(columns={'%':'Ethnic Origin 1 in %', \n                                                      '%.1':'Ethnic Origin 2 in %',\n                                                     '%.2':'Ethnic Origin 3 in %',\n                                                     '%.3':'Ethnic Origin 4 in %',\n                                                     '%.4':'Ethnic Origin 5 in %',\n                                                     '%.5':'Ethnic Origin 6 in %',\n                                                     '%.6':'Ethnic Origin 7 in %',\n                                                     '%.7':'Ethnic Origin 8 in %'})\nNorth_population_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#SCARBOROUGH population distribution by ethnicity \nScar_population_df = pd.read_html(html, header = 0)[15]\nScar_population_df = Scar_population_df.rename(columns={'%':'Ethnic Origin 1 in %', \n                                                      '%.1':'Ethnic Origin 2 in %',\n                                                     '%.2':'Ethnic Origin 3 in %',\n                                                     '%.3':'Ethnic Origin 4 in %',\n                                                     '%.4':'Ethnic Origin 5 in %',\n                                                     '%.5':'Ethnic Origin 6 in %',\n                                                     '%.6':'Ethnic Origin 7 in %',\n                                                     '%.7':'Ethnic Origin 8 in %'})\nScar_population_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#ETOBICOKE & YORK population distribution by ethnicity \nETY_population_df = pd.read_html(html, header = 0)[16]\nETY_population_df = ETY_population_df.rename(columns={'%':'Ethnic Origin 1 in %', \n                                                      '%.1':'Ethnic Origin 2 in %',\n                                                     '%.2':'Ethnic Origin 3 in %',\n                                                     '%.3':'Ethnic Origin 4 in %',\n                                                     '%.4':'Ethnic Origin 5 in %',\n                                                     '%.5':'Ethnic Origin 6 in %',\n                                                     '%.6':'Ethnic Origin 7 in %',\n                                                     '%.7':'Ethnic Origin 8 in %'})\nETY_population_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "d) Get location data using Foursquare"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\nFoursquare API is very usefule online application used my many developers & other application like Uber etc. In this project I have used it to retrieve informtion about the places present in the neighborhoods of Toronto. The API returns a JSON file and we need to turn that into a data-frame. Here I\u2019ve chosen 100 popular spots for each neighborhood within a radius of 1km."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n#Use geopy library to get the latitude and longitude values of New York City.\n\naddress = 'Toronto'\n\ngeolocator = Nominatim(user_agent=\"ny_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # map rendering library"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\nradius=1000\nurl = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&ll={},{}&v={}&radius={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION, radius)\nresults = requests.get(url).json()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n#Function to get the category\n\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n\n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import json\nfrom pandas.io.json import json_normalize\n\nvenues = results['response']['groups'][0]['items']\n\nnearby_venues = json_normalize(venues) # flatten JSON\n\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "LIMIT = 100\ntoronto_venues = getNearbyVenues(names=toronto_DF['Neighborhood'],\n                                   latitudes=toronto_DF['Latitude'],\n                                   longitudes=toronto_DF['Longitude']\n                                  )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_venues.head(10)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\ntoronto_venues.groupby('Neighborhood').count()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ":\nprint('There are {} uniques categories.'.format(len(toronto_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "There are 274 uniques categories.\nThere are 274 unique categories in which Indian Restaurant is one of them. We will do one hot encoding for getting dummies of venue category. So that we will calculate mean of all venue groupby there neighborhoods."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\ntoronto_onehot['Neighborhood'] = toronto_venues['Neighborhood']\n\nfixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\ntoronto_onehot = toronto_onehot[fixed_columns]\ntoronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\ntoronto_grouped"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\nprint (toronto_venues['Venue Category'].value_counts())"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n3. Exploratory Data Analysis"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "3.1 Folium Library and Leaflet Map\nFolium is a python library, I'm using it to draw an interactive leaflet map using coordinate data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map of New York using latitude and longitude values\nmap_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(toronto_DF['Latitude'], toronto_DF['Longitude'], toronto_DF['Borough'], toronto_DF['Neighborhood']):\n    label = '{},{}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n3.2 Relationship between neighborhood and Indian Restaurant\nFirst we will extract the Neighborhood and Indian Restaurant column from the above toronto dataframe for further analysis:"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_part = toronto_grouped[['Neighborhood', 'Indian Restaurant']]\ntoronto_part"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_merged = pd.merge(toronto_DF, toronto_part, on='Neighborhood')\ntoronto_merged"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Let's try Categorical plot \n\n%matplotlib inline\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfig = plt.figure(figsize=(19,9))\n\nsns.set(font_scale=1.1)\nsns.violinplot(y=\"Indian Restaurant\", x=\"Borough\", data=toronto_merged, cut=0);\n\nplt.title('Violin plots of Indian restaurants in Borough of Toronto', fontsize=14)\nplt.show()\n\n#This plot helps in identifying the boroughs with densely populated Indian restaurants.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Lets visualize the neighborhood with Indian Restaurants\n\ngraph = pd.DataFrame(toronto_onehot.groupby('Neighborhood')['Indian Restaurant'].sum())\ngraph = graph.sort_values(by ='Indian Restaurant', ascending=False)\ngraph.iloc[:14].plot(kind='bar', figsize=(10,6))\nplt.xlabel(\"Neighborhoods\")\nplt.ylabel(\"No of Indian Restaurant\")\nplt.title(\"Neighborhoods vs No of Indian Restaurant\")\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n3.3 Relationship between neighborhood and Indian popultion"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Merge all the population table with the ethnic percentage by neighborhood\nET = ETY_population_df.append(TEY_population_df,sort=True).reset_index()\nET.drop('index',axis=1,inplace=True)\nSN = North_population_df.append(Scar_population_df,sort=True).reset_index()\nSN.drop('index',axis=1,inplace=True)\npop_ethnic_df = SN.append(ET,sort=True).reset_index()\npop_ethnic_df.drop('index',axis=1,inplace=True)\npop_ethnic_df = pop_ethnic_df[['Riding', 'Population','Ethnic Origin #1', 'Ethnic Origin 1 in %','Ethnic Origin #2', 'Ethnic Origin 2 in %',\n                               'Ethnic Origin #3','Ethnic Origin 3 in %','Ethnic Origin #4', 'Ethnic Origin 4 in %','Ethnic Origin #5','Ethnic Origin 5 in %', \n                               'Ethnic Origin #6','Ethnic Origin 6 in %','Ethnic Origin #7', 'Ethnic Origin 7 in %','Ethnic Origin #8', 'Ethnic Origin 8 in %',\n                               'Ethnic Origin #9','Ethnic Origin 9 in %',\n                              ]]\npop_ethnic_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "From the above dataframe we can pickout the neighborhoods with highest Indian population percentage by using the below given method."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n#Filtering the riding with Indian ethnic crowd\ntemp = pop_ethnic_df.loc[(pop_ethnic_df['Ethnic Origin #1'] == 'East Indian')| \n                                      (pop_ethnic_df['Ethnic Origin #2'] == 'East Indian')|\n                                      (pop_ethnic_df['Ethnic Origin #3'] == 'East Indian')|\n                                      (pop_ethnic_df['Ethnic Origin #4'] == 'East Indian')|\n                                      (pop_ethnic_df['Ethnic Origin #5'] == 'East Indian')|\n                                      (pop_ethnic_df['Ethnic Origin #6'] == 'East Indian')|\n                                      (pop_ethnic_df['Ethnic Origin #7'] == 'East Indian')|\n                                      (pop_ethnic_df['Ethnic Origin #8'] == 'East Indian')|\n                                      (pop_ethnic_df['Ethnic Origin #9'] == 'East Indian')]\npop_indian_df = pd.DataFrame(temp).reset_index()\npop_indian_df.drop('index',axis=1,inplace=True)\n\npop_indian_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#retaining only Indian ethnic percentage & the neighborhood name \ncolumns_list = pop_indian_df.columns.to_list()\npop_indian_DF_with_percent = pd.DataFrame()\n#removing Riding & Population from the column names list\ndel columns_list[0]\ndel columns_list[0]\n\n\nfor i in range(0,pop_indian_df.shape[0]):\n    for j in columns_list:\n        print(j)\n        if pop_indian_df.at[i, j] == 'East Indian':\n            k = columns_list.index(j) + 1\n            percent_col = columns_list[k]\n            pop_indian_DF_with_percent = pop_indian_DF_with_percent.append({'Riding':pop_indian_df.at[i, 'Riding'], 'Population':pop_indian_df.at[i, 'Population']\n                                                                           , 'Ethnicity': pop_indian_df.at[i, j], 'Percentage': pop_indian_df.at[i, percent_col]},ignore_index=True)\n\npop_indian_DF_with_percent"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pop_indian_DF_with_percent['Indian Population'] = (pop_indian_DF_with_percent['Percentage'] * pop_indian_DF_with_percent['Population'])/100\npop_indian_DF_with_percent.drop(columns={'Percentage','Population','Ethnicity'},axis=1, inplace =True)\npop_indian_DF_with_percent.drop_duplicates(keep='first',inplace=True) \npop_indian_DF_with_percent"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "bar_graph = pop_indian_DF_with_percent.sort_values(by='Indian Population', ascending=False)\nbar_graph.plot(kind='bar',x='Riding', y='Indian Population',figsize=(12,8), color='brown')\nplt.title(\"Indian Population in each Neighborhood\")\nplt.xlabel(\"Neighborhoods\")\nplt.ylabel(\"Population\")\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\nThis analysis & visualization of the relationship between neighborhoods & indian population present in those neighborhoods helps us in identifying the highly populated indian neighborhoods. Once we identify those neighborhoods it helps us in deciding where to place the new Indian restaurant. Indian restaurant placed in an densely populated Indian neighborhood is more likely to get more Indian customers than a restaurant placed in a neighborhood with less or no Indian population. Thus this analysis helps in the determining the success of the new Indian restaurant."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n3.4 Relationship between Indian poplation and Indian restaurant"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "First get the list of neighborhoods present in the riding using the wikipedia geography section for each riding. Altering the riding names to match the wikipedia page so we can retrieve the neighborhoods present in those ridings"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Altering the list to match the wikipedia page so we can retrieve the neighborhoods present in those Ridings\nriding_list = pop_indian_DF_with_percent['Riding'].to_list()\nriding_list[riding_list.index('Scarborough Centre')] = 'Scarborough Centre (electoral district)'\nriding_list[riding_list.index('Scarborough North')] = 'Scarborough North (electoral district)'\nriding_list"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Scraping wiki page to get the neighborhoods of ech Ridings\nimport wikipedia\n\nRiding_neighborhood_df = pd.DataFrame()\n\nfor item in riding_list:\n    section = wikipedia.WikipediaPage(item).section('Geography')\n    start = section.index('neighbourhoods of') + 17\n    stop = section.index('.',start)\n    Riding_neighborhood_df = Riding_neighborhood_df.append({'Riding':item, 'Neighborhoods':section[start:stop]},ignore_index=True)\n    \n\nRiding_neighborhood_df = Riding_neighborhood_df[['Riding','Neighborhoods']]\nRiding_neighborhood_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Merging the pop_indian_DF_with_percent dataframe containing population information with the Riding_neighborhood_df dataframe.\n\nNeigh_pop = pd.merge(pop_indian_DF_with_percent, Riding_neighborhood_df, on='Riding')\n\nNeigh_pop.drop(columns=['Riding'],inplace =True)\nNeigh_pop"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Neigh_pop['split_neighborhoods'] = Neigh_pop['Neighborhoods'].str.split(',') \nNeigh_pop.drop(columns=['Neighborhoods'],inplace=True,axis=1)\nNeigh_pop = Neigh_pop.split_neighborhoods.apply(pd.Series).merge(Neigh_pop, left_index = True, right_index = True).drop([\"split_neighborhoods\"], axis = 1)\\\n                    .melt(id_vars = ['Indian Population'], value_name = \"Neighborhood\").drop(\"variable\", axis = 1).dropna()\n\nNeigh_pop.reset_index()\nNeigh_pop"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_part['split_neighborhoods'] = toronto_part['Neighborhood'].str.split(',') \ntoronto_part.drop(columns=['Neighborhood'],inplace=True,axis=1)\ntoronto_part = toronto_part.split_neighborhoods.apply(pd.Series).merge(toronto_part, left_index = True, right_index = True).drop([\"split_neighborhoods\"], axis = 1)\\\n                    .melt(id_vars = ['Indian Restaurant'], value_name = \"Neighborhood\").drop(\"variable\", axis = 1).dropna()\n\ntoronto_part.reset_index()\ntoronto_part"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pop_merged_restaurant_percent = pd.merge(Neigh_pop, toronto_part, on='Neighborhood')\npop_merged_restaurant_percent.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\nAfter performing the data cleaning & data analysis we can identify that their no big relationship established in terms of the Indian population & the popular Indian restaurants.\n\nThus this marks end of the data cleaning & analyses step in this project. Next we will look into the predictive modeling. In the predictive modelling we are going to use Clustering techniques since this is analysis of unlabelled data. K-Means clustering is used to perform the analysis of the data at hand."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n4. Predictive Modeling\n4.1 Clustering Neighborhoods of Toronto:\nFirst step in K-means clustering is to identify best K value meaning the number of clusters in a given dataset. To do so we are going to use the elbow method on the Toronto dataset with Indian restaurant percentage (i.e. toronto_merged dataframe)."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\nfrom sklearn.cluster import KMeans\n\ntoronto_part_clustering = toronto_part.drop('Neighborhood', 1)\n\n\nerror_cost = []\n\nfor i in range(3,11):\n    KM = KMeans(n_clusters = i, max_iter = 100)\n    try:\n        KM.fit(toronto_part_clustering)\n    except ValueError:\n        print(\"error on line\",i)\n    \n    \n    \n    \n    #calculate squared error for the clustered points\n    error_cost.append(KM.inertia_/100)\n\n#plot the K values aganist the squared error cost\nplt.plot(range(3,11), error_cost, color='r', linewidth='3')\nplt.xlabel('K values')\nplt.ylabel('Squared Error (Cost)')\nplt.grid(color='white', linestyle='-', linewidth=2)\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!conda install -c districtdatalabs yellowbrick\n\nfrom yellowbrick.cluster import KElbowVisualizer"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n# Instantiate the clustering model and visualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(model, k=(4,13))\n\nvisualizer.fit(toronto_part_clustering)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\nAfter analysing using elbow method using distortion score & Squared error for each K value, looks like K = 6 is the best value.\u00b6\nClustering the Toronto Neighborhood Using K-Means with K = 6"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kclusters = 6\n\ntoronto_part_clustering = toronto_part.drop('Neighborhood', 1)\n\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_part_clustering)\n\nkmeans.labels_"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#sorted_neighborhoods_venues.drop(['Cluster Labels'],axis=1,inplace=True)\ntoronto_part.insert(0, 'Cluster Labels', kmeans.labels_)\ntoronto_merged = toronto_DF\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntoronto_merged = toronto_merged.join(toronto_part.set_index('Neighborhood'), on='Neighborhood')\ntoronto_merged.dropna(subset=[\"Cluster Labels\"], axis=0, inplace=True)\ntoronto_merged.reset_index(drop=True, inplace=True)\ntoronto_merged['Cluster Labels'].astype(int)\ntoronto_merged.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let us see the clusters visually on the map with the help of Folium."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ":\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11, width='90%', height='70%')\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels'].astype(int)):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\nmap_clusters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "4.2 Examing the Clusters:\nWe have total of 6 clusters such as 0,1,2,3,4,5. Let us examine one after the other.\n\nCluster 0 contains all the neighborhoods which has least number of Indian restaurants. It is shown in red color in the map"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Cluster 0\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 0]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n# Cluster 1 contains the neighborhoods which is sparsely populated with Indian restaurants. \n# It is shown in purple color in the map.\n\n\n#Cluster 1\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 1]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Cluster 2 has no rows meaning no data points or neighborhood was near to this centroid.\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 2]\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Cluster 3 contains all the neighborhoods which is medium populated with Indian restaurants. \n# It is shown in blue color in the map.\n\n#Cluster 3\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 3]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Cluster 4 has no rows meaning no data points or neighborhood was near to this centroid.\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 4]\n"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "\n#Cluster 5 contains all the neighborhoods which is densely populated with Indian restaurants. \n#It is shown in Orange color in the map\n\n#Cluster 5\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 5]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "5. Results and Discussion:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "5.1 Results\nWe have reached the end of the analysis, in the result section we can document all the findinds from above clustering & visualization of the datas. In this project, as the business problem started with identifying a good neighborhood to open a new Indian restaurant, we looked into all the neighborhoods in Toronto, analysed the Indian population in each neighborhood & spread of Indian restaurants in those neighborhoods to come to conclusion about which neighborhood would be a better spot for opening a new Indian restaurant. I have used data from web resources like Wikipedia, geospatial coordinates of Toronto neighborhoods, and Foursquare API, to set up a very realistic data-analysis scenario. We have found out that \u2014\n\nIn those 11 boroughs we identified that only Central Toronto, Downtown Tronto, East Toronto, East York, North York & Scarborough boroughs have high amount of Indian restaurants with the help of Violin plots between Number of Indian restaurants in Borough of Toronto.\nIn all the ridings, Scarborough-Guildwood, Scarborough-Rouge Park, Scarborough Centre, Scarborough North, Humber River-Black Creek, Don Valley East, Scarborough Southwest, Don Valley North & Scarborough-Agincourt are the densely populated with Indian crowd ridings.\nWith the help of clusters examing & violin plots looks like Downtown Toronto, Central Toronto, East York are already densely populated with Indian restaurants. So it is better idea to leave those boroughs out and consider only Scarborough, East Toronto & North York for the new restaurant's location.\nAfter careful consideration it is a good idea to open a new Indian restaurant in Scarborough borough since it has high number of Indian population which gives a higher number of customers possibility and lower competition since very less Indian restaurants in the neighborhoods."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "5.2 Discussion\nAccording to this analysis, Scarborough borough will provide least competition for the new upcoming Indian restaurant as there is very little Indian restaurants spread or no Indian restaurants in neighborhoods. Also looking at the population distribution looks like it is densely populated with Indian crowd which helps the new restaurant by providing hig customer visit possibilty. So, definitely this region could potentially be a perfect place for starting a quality Indian restaurants. Some of the drawbacks of this analysis are \u2014 the clustering is completely based only on data obtained from Foursquare API. Also the Indian population distribution in each neighborhood is also based on the 2016 census which is not up-to date. Thus population distribution would have definitely changed by 2019 given 3 years gap in the data. Since population distribution of Indian crowd in each neighborhood & number of Indian restaurants are the major feature in this analysis and it is not fully up-to date data, this analysis is definitely not far from being conclusory & it has lot of areas where it can be imporved. However, it certainly provides us with some good insights, preliminary information on possibilites & a head start into this business problem by setting the step stones properly. Furthermore, this may also potentially vary depending on the type of clustering techniques that we use to examine the data."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "6. Conclusion:\nFinally to conclude this project, We have got a chance to on a business problem like how a real like data scientists would do. We have used many python libraries to fetch the data , to manipulate the contents & to analyze and visualize those datasets. We have made use of Foursquare API to explore the venues in enighborhoods of Toronto, then get good amount of data from Wikipedia which we scraped with help of Wikipedia python library and visualized using various plots present in seaborn & matplotlib. We also applied machine learning technique to to predict the output given the data and used Folium to visualize it on a map. Also, some of the drawbacks or areas of improvements shows us that this analysis can further be improved with help more data and different machine learning technique. Similarly we can use this project to analysis any scenario such opening a different cuisine or success of opening a new gym and etc. Hopefully, this project helps acts as initial guidance to take more complex real-life challenges using data-science."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\ntoronto_part.drop('Cluster Labels',axis=1, inplace=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Sources\n\nhttps://en.wikipedia.org/wiki/Toronto\n    \n    "
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}