{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "# Final IBM Capstone Project"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Introduction \nWelcome to the final IBM Capstone Project. \nNow that you have been equipped with the skills and the tools to use location data to explore a geographical location, over the course of two weeks, you will have the opportunity to be as creative as you want and come up with an idea to leverage the Foursquare location data to explore or compare neighborhoods or cities of your choice or to come up with a problem that you can use the Foursquare location data to solve. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## A. Introduction \n#### Discuss the business problem and who would be interested in this project\n\n### Opening a Chinese Restaurant in Toronto, Canada \nThe provincial capital of Ontario. With a recorded population of 2,731,571 in 2016, it is the most populous city in Canada and the fourth most populous city in North America. Toronto is an international centre of business, finance, arts, and culture, and is recognized as one of the most multicultural and cosmopolitan cities in the world.\n\nChinese food is a great, delectable meal! Starting a restaurant with a recognized and popular cuisine can have great potential.  \n\nWe will analyze the neighborhoods in Toronto to identify the most profitable area based on population density and ethnicity diversity. Toronto is a great place to start the restaurant, but we just need to make sure whether it is a profitable idea or not."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Target Audience\n- Business personal who are looking to open a restaraunt in Toronto\n- Investors looking for a potentially successful restauraunt\n- Freelancers looking to start a franchise \n- Data Scientists who wish to analyze Toronto's neighborhoods \n- New visitors to Toronto who love to eat sushi often "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## B. Data\n#### Describe the data that will be used to solve the problem and the source of the data."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### B.1 Data Sources\n\na. Toronto's Neighborhood information such as \n- Postal Codes\n- Boroughs\n- Neighborhood Names \nSource: https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\n\nb. Toronto's Neighborhood Geographical Information\n- Latitude \n- Longitude\nSource: https://cocl.us/Geospatial_data\n\nc. Population Distribution by Ethnic Diversity \n- Ethnic Origin \nSource: https://en.m.wikipedia.org/wiki/Demographics_of_Toronto#Ethnic_diversity)\n\nd. Toronto's Venues Locations, Names, Categories, Location (in Latitude and Longitude) \nvia Foursquare's explore API \nSource: https://developer.foursquare.com\n\n#### Explanation: \nBy combining all of these data sources, we can create a data summary that will allow target audiences to make the best educated decision for their restaurant location."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### B.2 Data Frame "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### B.2.a. Toronto's Neighborhood information\n\nGoal: Create a Data Frame with the following columns:\n- Postal Code\n- Borough\n- Neighborhood \n\n*Note\n- *Only the cells that have an assigned borough will be processed. Borough that is not assigned are ignored.\n- *More than one neighborhood can exist in one postal code area. For example, in the table on the Wikipedia page, you will notice that M5A is listed twice and has two neighborhoods: Harbourfront and Regent Park. These two rows will be combined into one row with the neighborhoods separated with a comma as shown in row 11 in the above table.\n- *If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Solving environment: done\n\n# All requested packages already installed.\n\n"
                }
            ],
            "source": "#Install Dependencies \n!conda install -c conda-forge wikipedia --yes \n\nimport pandas as pd\nimport numpy as np\nimport wikipedia as wp"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Download Source from Wikipedia\nsource = wp.page(\"List of postal codes of Canada: M\").html().encode(\"UTF-8\")\ndf = pd.read_html(source, header = 0)[0]\n\n#Data Cleaning Part 1: Unassigned Boroughs will be ignored\ndf = df[df.Borough != 'Not assigned']\ndf = df.rename(columns={'Postcode': 'Postal Code'})\n\n#Data Cleaning Part 2: Unassigned Neighborhoods will share same name as their Assigned Boroughs\nfor index, row in df.iterrows():\n    if row['Neighbourhood'] == 'Not assigned':\n        row['Neighbourhood'] = row['Borough']\n        \n#Data Cleaning Part 3: Place Multiple Neighborhoods in one Borough         \ndf = df.groupby(['Borough', 'Postal Code'])['Neighbourhood'].apply(list).apply(\n    lambda x:', '.join(x)).to_frame().reset_index()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Data Sample \ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### B.2.b. Toronto's Neighborhood Geographical Information\n\nGoal: Add to the Data Frame (Postal Code, Borough, Neighborhood) with the following columns:\n- Latitude\n- Longitude"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Download Dependencies \nimport io\nimport requests\n\n#Extract data from csv file \nurl = \"https://cocl.us/Geospatial_data\"\ngeo_list = requests.get(url).text\ngeo_list_df=pd.read_csv(io.StringIO(geo_list))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Data Sample \ngeo_list_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Merge Dataframe (DF) [Postal Code, Borough, Neighborhood] + Dataframe (GeoList) [Latitude, Longitude]\ntoronto_DF = pd.merge(df,geo_list_df, on='Postal Code')\n\n#Change Neighbo'u'rhood to Neighborhood \ntoronto_DF = toronto_DF.rename(columns={'Neighbourhood':'Neighborhood'})"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Data Sample \ntoronto_DF.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### B.2.c. Population Distribution by Ethnic Diversity \n\nGoal: Obtain data of each neighborhood's population in term of ethnic diversity and transfer it into the Jupyter notebook.By seeing each federal electoral districts, we can see the most populous ethnic group in each riding (AKA Neighborhood). "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#overall population distribution \nhtml = wp.page(\"Demographics of Toronto\").html().encode(\"UTF-8\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#TORONTO & EAST YORK population distribution by ethnicity \nTEY_population_df = pd.read_html(html, header = 0)[13]\nTEY_population_df = TEY_population_df.rename(columns={'%':'Ethnic Origin 1 in %', \n                                                      '%.1':'Ethnic Origin 2 in %',\n                                                     '%.2':'Ethnic Origin 3 in %',\n                                                     '%.3':'Ethnic Origin 4 in %',\n                                                     '%.4':'Ethnic Origin 5 in %',\n                                                     '%.5':'Ethnic Origin 6 in %',\n                                                     '%.6':'Ethnic Origin 7 in %',\n                                                     '%.7':'Ethnic Origin 8 in %',\n                                                     '%.8':'Ethnic Origin 9 in %'})"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#TORONTO & EAST YORK\nTEY_population_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#NORTH YORK population distribution by ethnicity \nNorth_population_df = pd.read_html(html, header = 0)[14]\nNorth_population_df = North_population_df.rename(columns={'%':'Ethnic Origin 1 in %', \n                                                      '%.1':'Ethnic Origin 2 in %',\n                                                     '%.2':'Ethnic Origin 3 in %',\n                                                     '%.3':'Ethnic Origin 4 in %',\n                                                     '%.4':'Ethnic Origin 5 in %',\n                                                     '%.5':'Ethnic Origin 6 in %',\n                                                     '%.6':'Ethnic Origin 7 in %',\n                                                     '%.7':'Ethnic Origin 8 in %'})"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#NORTH YORK \nNorth_population_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#SCARBOROUGH population distribution by ethnicity \nScar_population_df = pd.read_html(html, header = 0)[15]\nScar_population_df = Scar_population_df.rename(columns={'%':'Ethnic Origin 1 in %', \n                                                      '%.1':'Ethnic Origin 2 in %',\n                                                     '%.2':'Ethnic Origin 3 in %',\n                                                     '%.3':'Ethnic Origin 4 in %',\n                                                     '%.4':'Ethnic Origin 5 in %',\n                                                     '%.5':'Ethnic Origin 6 in %',\n                                                     '%.6':'Ethnic Origin 7 in %',\n                                                     '%.7':'Ethnic Origin 8 in %'})"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#SCARBOROUGH \nScar_population_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#ETOBICOKE & YORK population distribution by ethnicity \nETY_population_df = pd.read_html(html, header = 0)[16]\nETY_population_df = ETY_population_df.rename(columns={'%':'Ethnic Origin 1 in %', \n                                                      '%.1':'Ethnic Origin 2 in %',\n                                                     '%.2':'Ethnic Origin 3 in %',\n                                                     '%.3':'Ethnic Origin 4 in %',\n                                                     '%.4':'Ethnic Origin 5 in %',\n                                                     '%.5':'Ethnic Origin 6 in %',\n                                                     '%.6':'Ethnic Origin 7 in %',\n                                                     '%.7':'Ethnic Origin 8 in %'})"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#ETOBICOKE & YORK \nETY_population_df"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### B.2.d. Toronto's Venues Locations, Names, Categories, Location (in Latitude and Longitude) \nvia Foursquare's explore API \n\nUsing FourSquare API, we can find explore neighborhoods in Toronto and what kind of venues reside in each neighborhood. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Install Dependencies \n!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Use geopy library to get the latitude and longitude values of Toronto \naddress = 'Toronto'\n\ngeolocator = Nominatim(user_agent=\"ny_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Folium is a great visualization library. \n#It has the ability zoom in/out of map, and click on each circle mark to reveal the name of the \n#neighborhood and its respective borough.\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#We are using a 1 Km Radius \nradius=1000\nurl = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&ll={},{}&v={}&radius={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION, radius)\nresults = requests.get(url).json()\n\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n\n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#The API returned a JSON file. \n#Now we turn it into a pandas data frame. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Install Dependencies \nimport json\nfrom pandas.io.json import json_normalize\n\n#Panda Data Frame \nvenues = results['response']['groups'][0]['items']\n\nnearby_venues = json_normalize(venues) # flatten JSON\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Data Sample \nnearby_venues.sorted.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Continue to look for nearby venues\ndef getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Im going to look for the Top 100 venues \nLIMIT = 100\ntoronto_venues = getNearbyVenues(names=toronto_DF['Neighborhood'],\n                                   latitudes=toronto_DF['Latitude'],\n                                   longitudes=toronto_DF['Longitude'])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Data Sample \ntoronto_venues.head(10)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#I want to see how many existing Venue Categories (e.g. Park, Swim School, Hotel, Gym, etc)\ntoronto_venues.groupby('Neighborhood').count()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques categories.'.format(len(toronto_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Calculate the mean of all venue groupby in each neighborhood\ntoronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\ntoronto_onehot['Neighborhood'] = toronto_venues['Neighborhood']\n\nfixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\ntoronto_onehot = toronto_onehot[fixed_columns]\ntoronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\ntoronto_grouped"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Let's see how many categories there are\nprint (toronto_venues['Venue Category'].value_counts())"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## C. Methodology \n#### Represents the main component of the report where you discuss\n#### Describe any exploratory data analysis that you did, any inferential statistical testing that you performed, if any, and what machine learnings were used and why."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### C.1 Folium\n- Folium is a great visualization library. \n- It has the ability zoom in/out of map, and click on each circle mark to reveal the name of the neighborhood and its respective borough.\n\nGoal: Create a interactive leaflet map using our coordinate data "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map of Toronto using latitude and longitude\nmap_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(toronto_DF['Latitude'], toronto_DF['Longitude'], toronto_DF['Borough'], toronto_DF['Neighborhood']):\n    label = '{},{}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='yellow',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### C.2 Relationship between Neighborhood and Chinese Restaurant \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### C.2.a Data Frame \nGoal: Add to our dataframe (Borough, Postal Code, Neighborhood, Latitude, Longitude) with the following columns: \n- Cluster Labels \n- Chinese Restaurant (the mean of venue groupby) "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Create a Dataframe with the columns : Neighborhood, Chinese Restaurant \ntoronto_part = toronto_grouped[['Neighborhood', 'Chinese Restaurant']]\n#Data Sample\ntoronto_part.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Add Dataframe (Toronto Part)[Neighborhood, Chinese Restaurant] to \n# Dataframe(Toronto DF)[Borough, Postal Code, Neighborhood, Latitude, Longitude]\ntoronto_merged = pd.merge(toronto_DF, toronto_part, on='Neighborhood')\n#Data Sample\ntoronto_merged"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### C.2.b Bar Charts \nGoal: Identify which specific neighborhoods have the highest mean of chinese restaurants "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Install Dependencies \n#%matplotlib inline\n#import matplotlib as mpl\n#import matplotlib.pyplot as plt\n#import seaborn as sns\n\n#Create Plot with Neighborhood vs. Chinese Restaurant (Mean)\n#fig = plt.figure(figsize=(19,9))\n\n#sns.set(font_scale=1.1)\n#sns.violinplot(y=\"Chinese Restaurant\", x=\"Borough\", data=toronto_merged, cut=0);\n\n#plt.title('Mean of Chinese restaurants in each Borough (Toronto, Canada)', fontsize=15)\n#plt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#With boroughs visualized, now we will continue with Neighborhood\n\ngraph = pd.DataFrame(toronto_onehot.groupby('Neighborhood')['Chinese Restaurant'].sum())\ngraph = graph.sort_values(by ='Chinese Restaurant', ascending=False)\ngraph.iloc[:14].plot(kind='bar', figsize=(20,10))\nplt.xlabel(\"Neighborhoods\")\nplt.ylabel(\"Number of Chinese Restaurant\")\nplt.title(\"Neighborhoods vs Number of Chinese Restaurant\")\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### C.2 Relationship between Neighborhood and Chinese Population\nFun Fact: The Chinese Population Group made up for 11.1% of Toronto's total population (in 2016) \n\nGoal: Identify which specific neighborhoods have the highest ethnic percentage \n\nIn Section B.2.c. Population Distribution by Ethnic Diversity, we created four dataframes for each federal electoral district:\n- #TORONTO & EAST YORK (TEY_population_df)\n- #NORTH YORK (North_population_df)\n- #SCARBOROUGH (Scar_population_df)\n- #ETOBICOKE & YORK (ETY_population_df)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Merge all four dataframes \nET = ETY_population_df.append(TEY_population_df,sort=True).reset_index()\nET.drop('index',axis=1,inplace=True)\nSN = North_population_df.append(Scar_population_df,sort=True).reset_index()\nSN.drop('index',axis=1,inplace=True)\npop_ethnic_df = SN.append(ET,sort=True).reset_index()\npop_ethnic_df.drop('index',axis=1,inplace=True)\npop_ethnic_df = pop_ethnic_df[['Riding', 'Population','Ethnic Origin #1', 'Ethnic Origin 1 in %','Ethnic Origin #2', 'Ethnic Origin 2 in %',\n                               'Ethnic Origin #3','Ethnic Origin 3 in %','Ethnic Origin #4', 'Ethnic Origin 4 in %','Ethnic Origin #5','Ethnic Origin 5 in %', \n                               'Ethnic Origin #6','Ethnic Origin 6 in %','Ethnic Origin #7', 'Ethnic Origin 7 in %','Ethnic Origin #8', 'Ethnic Origin 8 in %',\n                               'Ethnic Origin #9','Ethnic Origin 9 in %',\n                              ]]\n#Now we have a dataframe with important columns: \n#Riding (aka Neighborhood), Population, Ethnic Origin # in Percentage\npop_ethnic_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "From the above dataframe we can pickout the neighborhoods with highest Indian population percentage by using the below given method."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#We're going to create a new dataframe(pop_chinese_df) \n#where the Ethnic Origin (from #1-#9) has at least one \"Chinese\" group\ntemp = pop_ethnic_df.loc[(pop_ethnic_df['Ethnic Origin #1'] == 'Chinese')| \n                                      (pop_ethnic_df['Ethnic Origin #2'] == 'Chinese')|\n                                      (pop_ethnic_df['Ethnic Origin #3'] == 'Chinese')|\n                                      (pop_ethnic_df['Ethnic Origin #4'] == 'Chinese')|\n                                      (pop_ethnic_df['Ethnic Origin #5'] == 'Chinese')|\n                                      (pop_ethnic_df['Ethnic Origin #6'] == 'Chinese')|\n                                      (pop_ethnic_df['Ethnic Origin #7'] == 'Chinese')|\n                                      (pop_ethnic_df['Ethnic Origin #8'] == 'Chinese')|\n                                      (pop_ethnic_df['Ethnic Origin #9'] == 'Chinese')]\npop_chinese_df = pd.DataFrame(temp).reset_index()\npop_chinese_df.drop('index',axis=1,inplace=True)\n\n#Data Sample \npop_chinese_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#retaining only Indian ethnic percentage & the neighborhood name \ncolumns_list = pop_indian_df.columns.to_list()\npop_indian_DF_with_percent = pd.DataFrame()\n\n#removing Riding & Population from the column names list\ndel columns_list[0]\ndel columns_list[0]\n\n\nfor i in range(0,pop_indian_df.shape[0]):\n    for j in columns_list:\n        print(j)\n        if pop_indian_df.at[i, j] == 'East Indian':\n            k = columns_list.index(j) + 1\n            percent_col = columns_list[k]\n            pop_indian_DF_with_percent = pop_indian_DF_with_percent.append({'Riding':pop_indian_df.at[i, 'Riding'], 'Population':pop_indian_df.at[i, 'Population']\n                                                                           , 'Ethnicity': pop_indian_df.at[i, j], 'Percentage': pop_indian_df.at[i, percent_col]},ignore_index=True)\n\npop_indian_DF_with_percent"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pop_indian_DF_with_percent['Indian Population'] = (pop_indian_DF_with_percent['Percentage'] * pop_indian_DF_with_percent['Population'])/100\npop_indian_DF_with_percent.drop(columns={'Percentage','Population','Ethnicity'},axis=1, inplace =True)\npop_indian_DF_with_percent.drop_duplicates(keep='first',inplace=True) \npop_indian_DF_with_percent"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "bar_graph = pop_indian_DF_with_percent.sort_values(by='Indian Population', ascending=False)\nbar_graph.plot(kind='bar',x='Riding', y='Indian Population',figsize=(12,8), color='brown')\nplt.title(\"Indian Population in each Neighborhood\")\nplt.xlabel(\"Neighborhoods\")\nplt.ylabel(\"Population\")\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\nThis analysis & visualization of the relationship between neighborhoods & indian population present in those neighborhoods helps us in identifying the highly populated indian neighborhoods. Once we identify those neighborhoods it helps us in deciding where to place the new Indian restaurant. Indian restaurant placed in an densely populated Indian neighborhood is more likely to get more Indian customers than a restaurant placed in a neighborhood with less or no Indian population. Thus this analysis helps in the determining the success of the new Indian restaurant."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n3.4 Relationship between Indian poplation and Indian restaurant"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "First get the list of neighborhoods present in the riding using the wikipedia geography section for each riding. Altering the riding names to match the wikipedia page so we can retrieve the neighborhoods present in those ridings"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Altering the list to match the wikipedia page so we can retrieve the neighborhoods present in those Ridings\nriding_list = pop_indian_DF_with_percent['Riding'].to_list()\nriding_list[riding_list.index('Scarborough Centre')] = 'Scarborough Centre (electoral district)'\nriding_list[riding_list.index('Scarborough North')] = 'Scarborough North (electoral district)'\nriding_list"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Scraping wiki page to get the neighborhoods of ech Ridings\nimport wikipedia\n\nRiding_neighborhood_df = pd.DataFrame()\n\nfor item in riding_list:\n    section = wikipedia.WikipediaPage(item).section('Geography')\n    start = section.index('neighbourhoods of') + 17\n    stop = section.index('.',start)\n    Riding_neighborhood_df = Riding_neighborhood_df.append({'Riding':item, 'Neighborhoods':section[start:stop]},ignore_index=True)\n    \n\nRiding_neighborhood_df = Riding_neighborhood_df[['Riding','Neighborhoods']]\nRiding_neighborhood_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Merging the pop_indian_DF_with_percent dataframe containing population information with the Riding_neighborhood_df dataframe.\n\nNeigh_pop = pd.merge(pop_indian_DF_with_percent, Riding_neighborhood_df, on='Riding')\n\nNeigh_pop.drop(columns=['Riding'],inplace =True)\nNeigh_pop"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Neigh_pop['split_neighborhoods'] = Neigh_pop['Neighborhoods'].str.split(',') \nNeigh_pop.drop(columns=['Neighborhoods'],inplace=True,axis=1)\nNeigh_pop = Neigh_pop.split_neighborhoods.apply(pd.Series).merge(Neigh_pop, left_index = True, right_index = True).drop([\"split_neighborhoods\"], axis = 1)\\\n                    .melt(id_vars = ['Indian Population'], value_name = \"Neighborhood\").drop(\"variable\", axis = 1).dropna()\n\nNeigh_pop.reset_index()\nNeigh_pop"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "toronto_part['split_neighborhoods'] = toronto_part['Neighborhood'].str.split(',') \ntoronto_part.drop(columns=['Neighborhood'],inplace=True,axis=1)\ntoronto_part = toronto_part.split_neighborhoods.apply(pd.Series).merge(toronto_part, left_index = True, right_index = True).drop([\"split_neighborhoods\"], axis = 1)\\\n                    .melt(id_vars = ['Indian Restaurant'], value_name = \"Neighborhood\").drop(\"variable\", axis = 1).dropna()\n\ntoronto_part.reset_index()\ntoronto_part"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pop_merged_restaurant_percent = pd.merge(Neigh_pop, toronto_part, on='Neighborhood')\npop_merged_restaurant_percent.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\nAfter performing the data cleaning & data analysis we can identify that their no big relationship established in terms of the Indian population & the popular Indian restaurants.\n\nThus this marks end of the data cleaning & analyses step in this project. Next we will look into the predictive modeling. In the predictive modelling we are going to use Clustering techniques since this is analysis of unlabelled data. K-Means clustering is used to perform the analysis of the data at hand."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\n4. Predictive Modeling\n4.1 Clustering Neighborhoods of Toronto:\nFirst step in K-means clustering is to identify best K value meaning the number of clusters in a given dataset. To do so we are going to use the elbow method on the Toronto dataset with Indian restaurant percentage (i.e. toronto_merged dataframe)."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\nfrom sklearn.cluster import KMeans\n\ntoronto_part_clustering = toronto_part.drop('Neighborhood', 1)\n\n\nerror_cost = []\n\nfor i in range(3,11):\n    KM = KMeans(n_clusters = i, max_iter = 100)\n    try:\n        KM.fit(toronto_part_clustering)\n    except ValueError:\n        print(\"error on line\",i)\n    \n    \n    \n    \n    #calculate squared error for the clustered points\n    error_cost.append(KM.inertia_/100)\n\n#plot the K values aganist the squared error cost\nplt.plot(range(3,11), error_cost, color='r', linewidth='3')\nplt.xlabel('K values')\nplt.ylabel('Squared Error (Cost)')\nplt.grid(color='white', linestyle='-', linewidth=2)\nplt.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!conda install -c districtdatalabs yellowbrick\n\nfrom yellowbrick.cluster import KElbowVisualizer"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n# Instantiate the clustering model and visualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(model, k=(4,13))\n\nvisualizer.fit(toronto_part_clustering)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\nAfter analysing using elbow method using distortion score & Squared error for each K value, looks like K = 6 is the best value.\u00b6\nClustering the Toronto Neighborhood Using K-Means with K = 6"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "kclusters = 6\n\ntoronto_part_clustering = toronto_part.drop('Neighborhood', 1)\n\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_part_clustering)\n\nkmeans.labels_"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#sorted_neighborhoods_venues.drop(['Cluster Labels'],axis=1,inplace=True)\ntoronto_part.insert(0, 'Cluster Labels', kmeans.labels_)\ntoronto_merged = toronto_DF\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntoronto_merged = toronto_merged.join(toronto_part.set_index('Neighborhood'), on='Neighborhood')\ntoronto_merged.dropna(subset=[\"Cluster Labels\"], axis=0, inplace=True)\ntoronto_merged.reset_index(drop=True, inplace=True)\ntoronto_merged['Cluster Labels'].astype(int)\ntoronto_merged.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let us see the clusters visually on the map with the help of Folium."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ":\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11, width='90%', height='70%')\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels'].astype(int)):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\nmap_clusters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "4.2 Examing the Clusters:\nWe have total of 6 clusters such as 0,1,2,3,4,5. Let us examine one after the other.\n\nCluster 0 contains all the neighborhoods which has least number of Indian restaurants. It is shown in red color in the map"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Cluster 0\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 0]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\n# Cluster 1 contains the neighborhoods which is sparsely populated with Indian restaurants. \n# It is shown in purple color in the map.\n\n\n#Cluster 1\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 1]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Cluster 2 has no rows meaning no data points or neighborhood was near to this centroid.\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 2]\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Cluster 3 contains all the neighborhoods which is medium populated with Indian restaurants. \n# It is shown in blue color in the map.\n\n#Cluster 3\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 3]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Cluster 4 has no rows meaning no data points or neighborhood was near to this centroid.\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 4]\n"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "\n#Cluster 5 contains all the neighborhoods which is densely populated with Indian restaurants. \n#It is shown in Orange color in the map\n\n#Cluster 5\ntoronto_merged.loc[toronto_merged['Cluster Labels'] == 5]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "5. Results and Discussion:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "5.1 Results\nWe have reached the end of the analysis, in the result section we can document all the findinds from above clustering & visualization of the datas. In this project, as the business problem started with identifying a good neighborhood to open a new Indian restaurant, we looked into all the neighborhoods in Toronto, analysed the Indian population in each neighborhood & spread of Indian restaurants in those neighborhoods to come to conclusion about which neighborhood would be a better spot for opening a new Indian restaurant. I have used data from web resources like Wikipedia, geospatial coordinates of Toronto neighborhoods, and Foursquare API, to set up a very realistic data-analysis scenario. We have found out that \u2014\n\nIn those 11 boroughs we identified that only Central Toronto, Downtown Tronto, East Toronto, East York, North York & Scarborough boroughs have high amount of Indian restaurants with the help of Violin plots between Number of Indian restaurants in Borough of Toronto.\nIn all the ridings, Scarborough-Guildwood, Scarborough-Rouge Park, Scarborough Centre, Scarborough North, Humber River-Black Creek, Don Valley East, Scarborough Southwest, Don Valley North & Scarborough-Agincourt are the densely populated with Indian crowd ridings.\nWith the help of clusters examing & violin plots looks like Downtown Toronto, Central Toronto, East York are already densely populated with Indian restaurants. So it is better idea to leave those boroughs out and consider only Scarborough, East Toronto & North York for the new restaurant's location.\nAfter careful consideration it is a good idea to open a new Indian restaurant in Scarborough borough since it has high number of Indian population which gives a higher number of customers possibility and lower competition since very less Indian restaurants in the neighborhoods."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "5.2 Discussion\nAccording to this analysis, Scarborough borough will provide least competition for the new upcoming Indian restaurant as there is very little Indian restaurants spread or no Indian restaurants in neighborhoods. Also looking at the population distribution looks like it is densely populated with Indian crowd which helps the new restaurant by providing hig customer visit possibilty. So, definitely this region could potentially be a perfect place for starting a quality Indian restaurants. Some of the drawbacks of this analysis are \u2014 the clustering is completely based only on data obtained from Foursquare API. Also the Indian population distribution in each neighborhood is also based on the 2016 census which is not up-to date. Thus population distribution would have definitely changed by 2019 given 3 years gap in the data. Since population distribution of Indian crowd in each neighborhood & number of Indian restaurants are the major feature in this analysis and it is not fully up-to date data, this analysis is definitely not far from being conclusory & it has lot of areas where it can be imporved. However, it certainly provides us with some good insights, preliminary information on possibilites & a head start into this business problem by setting the step stones properly. Furthermore, this may also potentially vary depending on the type of clustering techniques that we use to examine the data."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "6. Conclusion:\nFinally to conclude this project, We have got a chance to on a business problem like how a real like data scientists would do. We have used many python libraries to fetch the data , to manipulate the contents & to analyze and visualize those datasets. We have made use of Foursquare API to explore the venues in enighborhoods of Toronto, then get good amount of data from Wikipedia which we scraped with help of Wikipedia python library and visualized using various plots present in seaborn & matplotlib. We also applied machine learning technique to to predict the output given the data and used Folium to visualize it on a map. Also, some of the drawbacks or areas of improvements shows us that this analysis can further be improved with help more data and different machine learning technique. Similarly we can use this project to analysis any scenario such opening a different cuisine or success of opening a new gym and etc. Hopefully, this project helps acts as initial guidance to take more complex real-life challenges using data-science."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "\ntoronto_part.drop('Cluster Labels',axis=1, inplace=True)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Sources\n\nhttps://en.wikipedia.org/wiki/Toronto\n    \n    "
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}